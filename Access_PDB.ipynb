{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting organism information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pickle\n",
    "import multiprocessing\n",
    "import pandas as pd\n",
    "\n",
    "# Obtain the source organism ncbi scientific name from its pdb code using the PDB API\n",
    "def query_org(pdb):\n",
    "    response=requests.get(f'https://data.rcsb.org/rest/v1/core/entry/{pdb}')\n",
    "    if \"rcsb_entry_info\" in response.json() and \"polymer_entity_count\"  in response.json()[\"rcsb_entry_info\"]:\n",
    "        number_entities=response.json()[\"rcsb_entry_info\"][\"polymer_entity_count\"]\n",
    "        for entity in range(1,number_entities+1):\n",
    "            response=requests.get(f'https://data.rcsb.org/rest/v1/core/polymer_entity/{pdb}/{entity}')\n",
    "            if \"rcsb_entity_source_organism\" in response.json():\n",
    "                if \"ncbi_scientific_name\" in response.json()[\"rcsb_entity_source_organism\"][0].keys():\n",
    "                    return response.json()[\"rcsb_entity_source_organism\"][0][\"ncbi_scientific_name\"]\n",
    "                else:\n",
    "                    pass    # will create a None object even if we remove the else\n",
    "            else:\n",
    "                return[\"Error type 1\"] # Missing source organism is the database for this pdb code\n",
    "    else:\n",
    "        return[\"Error type 2\"]  # Missing the info about the number of entities in the database for this pdb code\n",
    "\n",
    "#Filter only the pdb codes related to E.coli source organism\n",
    "def coli_query_org(pdb):\n",
    "    if query_org(pdb)==\"Escherichia coli\":\n",
    "        return pdb\n",
    "\n",
    "#Filter only the pdb codes related to human source organism\n",
    "def human_query_org(pdb):\n",
    "    if query_org(pdb)==\"Homo sapiens\":\n",
    "        return pdb\n",
    "\n",
    "#Filter only the pdb codes related to T.maritima source organism\n",
    "def thermo_query_org(pdb):\n",
    "    if query_org(pdb)==\"Thermotoga maritima\":\n",
    "        return pdb\n",
    "\n",
    "###########\n",
    "# Part 1 - Creating a pickle file with several objects, each a part of the list of whether the pdb is in ecoli or not\n",
    "###########\n",
    "\n",
    "# Create pickle file with header describing it\n",
    "\n",
    "coli_pdb_lst=\"This is the header of the pickle file of the pdb codes for ecoli source organism proteins\"\n",
    "with open(\"ecoli_pdb_lsts.pickle\",\"wb\") as pickle_output:\n",
    "    pickle.dump(coli_pdb_lst, pickle_output)\n",
    "\n",
    "human_pdb_lst=\"This is the header of the pickle file of the pdb codes for human source organism proteins\"\n",
    "with open(\"human_pdb_lsts.pickle\",\"wb\") as pickle_output:\n",
    "    pickle.dump(human_pdb_lst, pickle_output)\n",
    "\n",
    "thermo_pdb_lst=\"This is the header of the pickle file of the pdb codes for thermotoga maritima source organism proteins\"\n",
    "with open(\"thermo_pdb_lsts.pickle\",\"wb\") as pickle_output:\n",
    "    pickle.dump(thermo_pdb_lst, pickle_output)\n",
    "\n",
    "# Create a uniq list of all the pdb names found in DE-STRESS: pdb_list\n",
    "with open(\"DE-STRESS_data.pickle\", \"rb\") as data_output:\n",
    "    lst_dics=pickle.load(data_output)\n",
    "    pdblist=[dic['PDB Code'].upper() for dic in (lst_dics) if dic!=None] \n",
    "    pdb_list=list(pd.unique(pdblist)) \n",
    "\n",
    "    # Create several small lists of pdb codes with the source organism ncbi scientific name Escherichia coli\n",
    "    if __name__==\"__main__\":\n",
    "        for i in range((len(pdb_list)//100)+1):#\n",
    "            print(f\"Round number {i+1}\")\n",
    "            pdb_sublst=pdb_list[i*100:(i+1)*100]\n",
    "            with multiprocessing.Pool(7) as p:\n",
    "                data=p.map(coli_query_org, pdb_sublst)\n",
    "                with open(\"ecoli_pdb_lsts.pickle\",\"ab\") as pickle_output:       \n",
    "                    pickle.dump(data, pickle_output)\n",
    "    \n",
    "    # Create several small lists of pdb codes with the source organism ncbi scientific name Homo sapiens\n",
    "    if __name__==\"__main__\":\n",
    "        for i in range((len(pdb_list)//100)+1):#\n",
    "            print(f\"Round number {i+1}\")\n",
    "            pdb_sublst=pdb_list[i*100:(i+1)*100]\n",
    "            with multiprocessing.Pool(7) as p:\n",
    "                data=p.map(human_query_org, pdb_sublst)\n",
    "                with open(\"human_pdb_lsts.pickle\",\"ab\") as pickle_output:      \n",
    "                    pickle.dump(data, pickle_output)\n",
    "    # Create several small lists of pdb codes with the source organism ncbi scientific name Thermotoga maritima\n",
    "    if __name__==\"__main__\":\n",
    "        for i in range((len(pdb_list)//100)+1):#\n",
    "            print(f\"Round number {i+1}\")\n",
    "            pdb_sublst=pdb_list[i*100:(i+1)*100]\n",
    "            with multiprocessing.Pool(7) as p:\n",
    "                data=p.map(thermo_query_org, pdb_sublst)\n",
    "                with open(\"thermo_pdb_lsts.pickle\",\"ab\") as pickle_output:\n",
    "                    pickle.dump(data, pickle_output)\n",
    "\n",
    "\n",
    "###########\n",
    "# Part 2 - join all the small lists into one big one\n",
    "############\n",
    "\n",
    "#For E.coli \n",
    "with open(\"ecoli_pdb_lsts.pickle\",\"rb\") as pickle_output:\n",
    "    lst=[]\n",
    "    count=0\n",
    "    while 1:\n",
    "        count+=1\n",
    "        try:\n",
    "            data=pickle.load(pickle_output)\n",
    "            if count>=2:\n",
    "                lst+=(data)\n",
    "        except EOFError:\n",
    "            break\n",
    "    with open(\"ecoli_pdb_lst.pickle\",\"wb\") as pickle_input:      \n",
    "         pickle.dump(lst, pickle_input)\n",
    "\n",
    "#For humans\n",
    "with open(\"human_pdb_lsts.pickle\",\"rb\") as pickle_output:\n",
    "    lst=[]\n",
    "    count=0\n",
    "    while 1:\n",
    "        count+=1\n",
    "        try:\n",
    "            data=pickle.load(pickle_output)\n",
    "            if count>=2:\n",
    "                lst+=(data)\n",
    "        except EOFError:\n",
    "            break\n",
    "    with open(\"human_pdb_lst.pickle\",\"wb\") as pickle_input:      \n",
    "         pickle.dump(lst, pickle_input)\n",
    "\n",
    "#For T.maritima\n",
    "with open(\"thermo_pdb_lsts.pickle\",\"rb\") as pickle_output:\n",
    "    lst=[]\n",
    "    count=0\n",
    "    while 1:\n",
    "        count+=1\n",
    "        try:\n",
    "            data=pickle.load(pickle_output)\n",
    "            if count>=2:\n",
    "                lst+=(data)\n",
    "        except EOFError:\n",
    "            break\n",
    "    with open(\"thermo_pdb_lst.pickle\",\"wb\") as pickle_input:      \n",
    "         pickle.dump(lst, pickle_input)\n",
    "\n",
    "\n",
    "###########\n",
    "# Part 3 - Remove None objects from list\n",
    "#############\n",
    "\n",
    "#For E.coli\n",
    "with open(\"ecoli_pdb_lst.pickle\",\"rb\") as pickle_output:\n",
    "    data=pickle.load(pickle_output)\n",
    "    lst=[]\n",
    "    for element in data:\n",
    "        if element != None:\n",
    "            lst.append(element)\n",
    "    with open(\"ECOLI_PDBs.pickle\",\"wb\") as pickle_input:      \n",
    "        pickle.dump(lst, pickle_input)\n",
    "\n",
    "#For humans\n",
    "with open(\"human_pdb_lst.pickle\",\"rb\") as pickle_output:\n",
    "    data=pickle.load(pickle_output)\n",
    "    lst=[]\n",
    "    for element in data:\n",
    "        if element != None:\n",
    "            lst.append(element)\n",
    "    with open(\"HUMAN_PDBs.pickle\",\"wb\") as pickle_input:      \n",
    "        pickle.dump(lst, pickle_input)\n",
    "\n",
    "#for T.maritima\n",
    "with open(\"thermo_pdb_lst.pickle\",\"rb\") as pickle_output:\n",
    "    data=pickle.load(pickle_output)\n",
    "    lst=[]\n",
    "    for element in data:\n",
    "        if element != None:\n",
    "            lst.append(element)\n",
    "    with open(\"THERMO_PDBs.pickle\",\"wb\") as pickle_input:      \n",
    "        pickle.dump(lst, pickle_input)\n",
    "\n",
    "\n",
    "############\n",
    "# Part 4 - Create a list of dictionaries where each dictionary corresponds to a peptide chain which pdb code refers to the source organism\n",
    "############\n",
    "\n",
    "Ecoli_path=\"path_of_file\\ECOLI_PDBs.pickle\"\n",
    "Human_path=\"path_of_file\\HUMAN_PDBs.pickle\"\n",
    "Thermo_path=\"path_of_file\\THERMO_PDBs.pickle\"\n",
    "DESTRESS_path=\"path_of_file\\DE-STRESS_data.pickle\"\n",
    "\n",
    "#Create list of dictionaries for E.coli proteins\n",
    "with open(Ecoli_path,\"rb\") as pickle_output:\n",
    "    ecoli_pdb_lst=pickle.load(pickle_output)\n",
    "\n",
    "with open(DESTRESS_path,'rb') as pickle_output:\n",
    "    dic=pickle.load(pickle_output)\n",
    "    Ecoli_lst_of_dics=[]\n",
    "    for i in range(len(dic)):\n",
    "        ecoli_dic={\"Chain ID\":\"\", 'Mean Pack Density':\"\",'Chain Length':\"\",\n",
    "        'Rotatory Bonds':\"\",'Rosetta Energy': \"\",'PDB Code':\"\", 'Exp Method':\"\", 'Bude Score':\"\",\n",
    "         'Evo Score':\"\", 'DFire Score':\"\", 'Aggre Score':\"\"}\n",
    "        if dic[i]!=None:\n",
    "            if dic[i][\"PDB Code\"].upper() in ecoli_pdb_lst:\n",
    "                ecoli_dic[\"Chain ID\"]=dic[i][\"Chain ID\"]\n",
    "                ecoli_dic[\"Mean Pack Density\"]=dic[i][\"Mean Pack Density\"]\n",
    "                ecoli_dic[\"Chain Length\"]=dic[i][\"Chain Length\"]\n",
    "                ecoli_dic[\"Rotatory Bonds\"]=dic[i][\"Rotatory Bonds\"]\n",
    "                ecoli_dic[\"Rosetta Energy\"]=dic[i][\"Rosetta Energy\"]\n",
    "                ecoli_dic[\"PDB Code\"]=dic[i][\"PDB Code\"]\n",
    "                ecoli_dic[\"Exp Method\"]=dic[i][\"Exp Method\"]\n",
    "                ecoli_dic[\"Bude Score\"]=dic[i][\"Bude Score\"]\n",
    "                ecoli_dic[\"Evo Score\"]=dic[i][\"Evo Score\"]\n",
    "                ecoli_dic[\"DFire Score\"]=dic[i][\"DFire Score\"]\n",
    "                ecoli_dic[\"Aggre Score\"]=dic[i][\"Aggre Score\"]\n",
    "                Ecoli_lst_of_dics.append(ecoli_dic)\n",
    "    with open(\"Ecoli_Data.pickle\",\"wb\") as pickle_input:\n",
    "        pickle.dump(Ecoli_lst_of_dics,pickle_input)\n",
    "\n",
    "\n",
    "#Create list of dictionaries for human proteins\n",
    "with open(Human_path,\"rb\") as pickle_output:\n",
    "    Human_pdb_lst=pickle.load(pickle_output)\n",
    "\n",
    "with open(DESTRESS_path,'rb') as pickle_output:\n",
    "    dic=pickle.load(pickle_output)\n",
    "    Human_lst_of_dics=[]\n",
    "    for i in range(len(dic)):\n",
    "        Human_dic={\"Chain ID\":\"\", 'Mean Pack Density':\"\",'Chain Length':\"\",\n",
    "        'Rotatory Bonds':\"\",'Rosetta Energy': \"\",'PDB Code':\"\", 'Exp Method':\"\", 'Bude Score':\"\",\n",
    "         'Evo Score':\"\", 'DFire Score':\"\", 'Aggre Score':\"\"}\n",
    "        if dic[i]!=None:\n",
    "            if dic[i][\"PDB Code\"].upper() in Human_pdb_lst:\n",
    "                Human_dic[\"Chain ID\"]=dic[i][\"Chain ID\"]\n",
    "                Human_dic[\"Mean Pack Density\"]=dic[i][\"Mean Pack Density\"]\n",
    "                Human_dic[\"Chain Length\"]=dic[i][\"Chain Length\"]\n",
    "                Human_dic[\"Rotatory Bonds\"]=dic[i][\"Rotatory Bonds\"]\n",
    "                Human_dic[\"Rosetta Energy\"]=dic[i][\"Rosetta Energy\"]\n",
    "                Human_dic[\"PDB Code\"]=dic[i][\"PDB Code\"]\n",
    "                Human_dic[\"Exp Method\"]=dic[i][\"Exp Method\"]\n",
    "                Human_dic[\"Bude Score\"]=dic[i][\"Bude Score\"]\n",
    "                Human_dic[\"Evo Score\"]=dic[i][\"Evo Score\"]\n",
    "                Human_dic[\"DFire Score\"]=dic[i][\"DFire Score\"]\n",
    "                Human_dic[\"Aggre Score\"]=dic[i][\"Aggre Score\"]\n",
    "                Human_lst_of_dics.append(Human_dic)\n",
    "        \n",
    "    with open(\"Human_Data.pickle\",\"wb\") as pickle_input:\n",
    "        pickle.dump(Human_lst_of_dics,pickle_input)\n",
    "\n",
    "\n",
    "#Create list of dictionaries for T.maritima proteins\n",
    "with open(Thermo_path,\"rb\") as pickle_output:\n",
    "    thermo_pdb_lst=pickle.load(pickle_output)\n",
    "\n",
    "with open(DESTRESS_path,'rb') as pickle_output:\n",
    "    dic=pickle.load(pickle_output)\n",
    "    Thermo_lst_of_dics=[]\n",
    "    for i in range(len(dic)):\n",
    "        thermo_dic={\"Chain ID\":\"\", 'Mean Pack Density':\"\",'Chain Length':\"\",\n",
    "        'Rotatory Bonds':\"\",'Rosetta Energy': \"\",'PDB Code':\"\", 'Exp Method':\"\", 'Bude Score':\"\",\n",
    "         'Evo Score':\"\", 'DFire Score':\"\", 'Aggre Score':\"\"}\n",
    "        if dic[i]!=None:\n",
    "            if dic[i][\"PDB Code\"].upper() in thermo_pdb_lst:\n",
    "                thermo_dic[\"Chain ID\"]=dic[i][\"Chain ID\"]\n",
    "                thermo_dic[\"Mean Pack Density\"]=dic[i][\"Mean Pack Density\"]\n",
    "                thermo_dic[\"Chain Length\"]=dic[i][\"Chain Length\"]\n",
    "                thermo_dic[\"Rotatory Bonds\"]=dic[i][\"Rotatory Bonds\"]\n",
    "                thermo_dic[\"Rosetta Energy\"]=dic[i][\"Rosetta Energy\"]\n",
    "                thermo_dic[\"PDB Code\"]=dic[i][\"PDB Code\"]\n",
    "                thermo_dic[\"Exp Method\"]=dic[i][\"Exp Method\"]\n",
    "                thermo_dic[\"Bude Score\"]=dic[i][\"Bude Score\"]\n",
    "                thermo_dic[\"Evo Score\"]=dic[i][\"Evo Score\"]\n",
    "                thermo_dic[\"DFire Score\"]=dic[i][\"DFire Score\"]\n",
    "                thermo_dic[\"Aggre Score\"]=dic[i][\"Aggre Score\"]\n",
    "                Thermo_lst_of_dics.append(thermo_dic)\n",
    "    with open(\"Thermo_Data.pickle\",\"wb\") as pickle_input:\n",
    "        pickle.dump(Thermo_lst_of_dics,pickle_input)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fcc9d14f13fdb1a17c1463029b9ae143e53bd3aa78ed9c0acd3ffe70e799f014"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
